mean(func1_airco$Sub_metering_3 < 1) |
mean(func1_airco$Sub_metering_3 > 4) &
mean(func1_airco$Sub_metering_3 < 10)){
airco <- "Your air conditioning is on"
} else {
airco <- "Your air conditioning is off"
}
}
if(Water_heater == "Your water heater is on"){
if(max(func1_airco$Sub_metering_3) > 20){
"Your air conditioning is on"
} else {
"Your air conditioning is off"
}
}
#list both results in a list so it can be returned
sub_meter_3_result <- list(Water_heater, airco)
return(sub_meter_3_result)
}
sub_meter3_on()
#first name the function and make it ask the person calling for it what time he wants to know what is going on
sub_meter3_on <- function(){
func1_year <- readline("What year is it?")
func1_month <- readline("What month is it?")
func1_day <- readline("What day of the month is it?")
func1_hrs <- readline("What time is it (hrs)?")
func1_mins <- readline("What time is it (mins)?")
#transform the inputs to numbereric valeues that can be used to call the specific date from the full dataset
func1_year <- as.numeric(unlist(strsplit(func1_year, ",")))
func1_month <- as.numeric(unlist(strsplit(func1_month, ",")))
func1_day <- as.numeric(unlist(strsplit(func1_day, ",")))
func1_hrs <- as.numeric(unlist(strsplit(func1_hrs, ",")))
func1_mins <- as.numeric(unlist(strsplit(func1_mins, ",")))
#filter the full dataset to get the specific time period the person calling for the function wanted
func1_heater <- Full_dataset %>%
filter(Year == func1_year,
Month == func1_month,
Day == func1_day,
Hour ==  func1_hrs,
Minute == func1_mins)
#for air conditioner the time must be taken a bit more broad because when its on it can have 0 kWh on a specific moment but not averaged
func1_airco <- Full_dataset %>%
filter(Year == func1_year,
Month == func1_month,
Day == func1_day,
Hour ==  func1_hrs,
Minute > (func1_mins - 10),
Minute < (func1_mins + 10))
#provide condition whether sub_meter3 gives indication that the water heater is on
if(func1_heater$Sub_metering_3 > 15){
Water_heater <- "Your water heater is on"
} else {
Water_heater <- "Your water heater is off"
}
#provide conditions whether sub_meter3 gives indication that the air conditioner is on
if(Water_heater == "Your water heater is off"){
if(mean(func1_airco$Sub_metering_3) > 0 &
mean(func1_airco$Sub_metering_3 < 1) |
mean(func1_airco$Sub_metering_3 > 4) &
mean(func1_airco$Sub_metering_3 < 10)){
airco <- "Your air conditioning is on"
} else {
airco <- "Your air conditioning is off"
}
}
if(Water_heater == "Your water heater is on"){
if(max(func1_airco$Sub_metering_3) > 20){
airco <- "Your air conditioning is on"
} else {
airco <- "Your air conditioning is off"
}
}
#list both results in a list so it can be returned
sub_meter_3_result <- list(Water_heater, airco)
return(sub_meter_3_result)
}
sub_meter3_on()
View(sub_meter3_on)
View(data_1_day)
View(data_1_day)
View(data_1_day)
View(data_1_day)
nrow(data_1_day==1)
nrow(data_1_day == 1)
nrow(data_1_day == 0)
nrow(data_1_day)
#first name the function and make it ask the person calling for it what time he wants to know what is going on
sub_meter3_on <- function(){
func1_year <- readline("What year is it?")
func1_month <- readline("What month is it?")
func1_day <- readline("What day of the month is it?")
func1_hrs <- readline("What time is it (hrs)?")
func1_mins <- readline("What time is it (mins)?")
#transform the inputs to numbereric valeues that can be used to call the specific date from the full dataset
func1_year <- as.numeric(unlist(strsplit(func1_year, ",")))
func1_month <- as.numeric(unlist(strsplit(func1_month, ",")))
func1_day <- as.numeric(unlist(strsplit(func1_day, ",")))
func1_hrs <- as.numeric(unlist(strsplit(func1_hrs, ",")))
func1_mins <- as.numeric(unlist(strsplit(func1_mins, ",")))
#filter the full dataset to get the specific time period the person calling for the function wanted
func1_heater <- Full_dataset %>%
filter(Year == func1_year,
Month == func1_month,
Day == func1_day,
Hour ==  func1_hrs,
Minute == func1_mins)
#for air conditioner the time must be taken a bit more broad because when its on it can have 0 kWh on a specific moment but not averaged
func1_airco <- Full_dataset %>%
filter(Year == func1_year,
Month == func1_month,
Day == func1_day,
Hour ==  func1_hrs,
Minute > (func1_mins - 5),
Minute < (func1_mins + 5))
#If both items are on, we need a broader range to test since we need to find some of the maximums
func1_both <- Full_dataset %>%
filter(Year == func1_year,
Month == func1_month,
Day == func1_day,
Hour ==  func1_hrs,
Minute > (func1_mins - 60),
Minute < (func1_mins + 60))
#provide condition whether sub_meter3 gives indication that the water heater is on
if(func1_heater$Sub_metering_3 > 15){
Water_heater <- "Your water heater is on"
} else {
Water_heater <- "Your water heater is off"
}
#provide conditions whether sub_meter3 gives indication that the air conditioner is on
if(mean(func1_airco$Sub_metering_3) > 0 &
mean(func1_airco$Sub_metering_3 < 1) |
mean(func1_airco$Sub_metering_3 > 4) &
mean(func1_airco$Sub_metering_3 < 10) |
max(func1_both$Sub_metering_3 > 25) |
max(func1_both$Sub_metering_3 > 17) &
nrow(filter(func1_both , Sub_metering_3 == 1)) > 12
){
airco <- "Your air conditioning is on"
} else {
airco <- "Your air conditioning is off"
}
#list both results in a list so it can be returned
sub_meter_3_result <- list(Water_heater, airco)
return(sub_meter_3_result)
}
View(sub_meter3_on)
sub_meter3_on
sub_meter3_on()
pacman::p_load('dplyr','bbplot', 'lubridate', 'RMySQL', 'tidyr',
'gapminder', 'readr', 'ggplot2', 'forecast',
'ggfortify','forcats', 'R.utils', 'plotly', 'prophet')
library(gtrendsR)
google.trends = gtrends(c("porn"), gprop = "web", time = "all")
Pr0n <- google.trends["interest_over_time"]
Pr0n <- google.trends[["interest_over_time"]]
class(pr0n)
class(Pr0n)
View(Pr0n)
Pr0n <- Pr0n %>% select(ds = date, y = hits)
View(Pr0n)
TS_dataset_Pr0n <- prophet(Pr0n, yearly.seasonality=TRUE)
TS_future_Pr0n <- make_future_dataframe(TS_dataset_Pr0n, periods = 24, freq = "month")
forecast_Pr0n <- predict(TS_dataset_Pr0n, TS_future_Pr0n)
plot(TS_dataset_Pr0n, forecast_Pr0n)
prophet_plot_components(TS_dataset_Pr0n, forecast_Pr0n)
plot(TS_dataset_Pr0n, forecast_Pr0n)
prophet_plot_components(TS_dataset_Pr0n, forecast_Pr0n)
source('C:/Users/Jeroen/Desktop/Ubiqum/IoT Analytics/Task 1 - Domain Research and Exploratory Data Analysis/Code/Part 1 - General data setup.R', echo=TRUE)
source('C:/Users/Jeroen/Desktop/Ubiqum/IoT Analytics/Task 2 - Visualize and Analyze Energy Data/Code/Part 3 - Time series setup.R', echo=TRUE)
library(keras)
install_keras()
install_tenserflow()
mnist <- dataset_mnist()
install.packages("keras", type = "source")
install.packages("keras", type = "source")
library(keras)
install_keras()
library(keras)
mnist <- dataset_mnist()
install_keras(method = c("auto", "virtualenv", "conda"),
conda = "auto", version = "default", tensorflow = "default",
extra_packages = c("tensorflow-hub"))
install_keras(method = c("auto", "virtualenv", "conda"),
conda = "auto", version = "default", tensorflow = "default",
extra_packages = c("tensorflow-hub"))
install_keras(method = c("auto", "virtualenv", "conda"),
conda = "auto", version = "default", tensorflow = "default",
extra_packages = c("tensorflow-hub"))
library(keras)
install_keras(method = c("auto", "virtualenv", "conda"),
conda = "auto", version = "default", tensorflow = "default",
extra_packages = c("tensorflow-hub"))
install.packages("tensorflow")
install.packages("keras")
library("keras")
install_keras()
mnist <- dataset_mnist()
set.seed(123)
#Make training and testing sets
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
# reshape
x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
set.seed(123)
#take the MNIST number data
mnist <- dataset_mnist()
#Make training and testing sets of the x data (3-d array (images,width,height) of grayscale values).
x_train <- mnist$train$x
x_test <- mnist$test$x
#Make training and testing sets of the y data (integer vector with values ranging from 0 to 9).
y_train <- mnist$train$y
y_test <- mnist$test$y
x_train
#Reshape the image pixel matrix into a vector (24x 24 becomes a vector of 784)
x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_train
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
y_test
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
y_train
y_test <- to_categorical(y_test, 10)
y_train
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 10, activation = 'softmax')
model
model <- keras_model_sequential()
model
model %>%
#this layer gives the length of the INPUT data (784), together with the amount different color values (256)
layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%
layer_dropout(rate = 0.4) %>%
#This is the second layer in the model, for which the algorithm finds itself chooses what patterns it is looking for
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
#this layer gives the length of the OUTPUT data (a value between 0-9).
#The softmax parameter tells the model to give a probability for each of these 10 values. The highest probability wins
layer_dense(units = 10, activation = 'softmax')
summary(model)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
history <- model %>% fit(
x_train, y_train,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
model %>% evaluate(x_test, y_test)
plot(history)
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
x_test <- x_test / 255
y_test <- to_categorical(y_test, 10)
model %>% evaluate(x_test, y_test)
y_test <- to_categorical(y_test, 10)
model %>% evaluate(x_test, y_test)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
?register_google
register_google
register_google()
source('C:/Users/Jeroen/Desktop/Ubiqum/IoT Analytics/Task 3 - Techniques for Wifi Locationing/Code/1) Partition training and testsets.R', echo=TRUE)
#This file will create the train various models and save the results in a RDS file
#For more information, visit http://archive.ics.uci.edu/ml/datasets/UJIIndoorLoc
#########################################################################################
#set working directory to get the resultss
setwd("C:/Users/Jeroen/Desktop/Ubiqum/IoT Analytics/Task 3 - Techniques for Wifi Locationing/Excel datafiles/Results")
#read results into R
predictions <- readRDS("2019-03-06 predicted values")
results <- readRDS("Results of loop 2019-03-06")
#add all actual y values in 1 dataframe with the results
y_df_test <- data.frame(y_list_test)
remove(y_list_test)
all_y_values <- merge(y_df_test, data.frame(predictions))
View(all_y_values)
#This file will create the train various models and save the results in a RDS file
#For more information, visit http://archive.ics.uci.edu/ml/datasets/UJIIndoorLoc
#########################################################################################
#set working directory to get the resultss
setwd("C:/Users/Jeroen/Desktop/Ubiqum/IoT Analytics/Task 3 - Techniques for Wifi Locationing/Excel datafiles/Results")
#read results into R
predictions <- readRDS("2019-03-06 predicted values")
results <- readRDS("Results of loop 2019-03-06")
#add all actual y values in 1 dataframe with the results
y_df_test <- data.frame(y_list_test)
#add all actual y values in 1 dataframe with the results
y_df_test <- data.frame(y_list_test)
source('C:/Users/Jeroen/Desktop/Ubiqum/IoT Analytics/Task 3 - Techniques for Wifi Locationing/Code/1) Partition training and testsets.R', echo=TRUE)
y_list_test
#add all actual y values in 1 dataframe with the results
y_list_test[[1]]
#add all actual y values in 1 dataframe with the results
class(y_list_test[[1]])
#add all actual y values in 1 dataframe with the results
class(y_list_test[1])
#add all actual y values in 1 dataframe with the results
y_list_test[[1]]
class(predictions)
#This file will create the train various models and save the results in a RDS file
#For more information, visit http://archive.ics.uci.edu/ml/datasets/UJIIndoorLoc
#########################################################################################
#set working directory to get the resultss
setwd("C:/Users/Jeroen/Desktop/Ubiqum/IoT Analytics/Task 3 - Techniques for Wifi Locationing/Excel datafiles/Results")
#read results into R
predictions <- readRDS("2019-03-06 predicted values")
results <- readRDS("Results of loop 2019-03-06")
class(predictions)
y_df_test <- data.frame(y_list_test)
predictions <- data.frame(predictions)
#This file will create the train various models and save the results in a RDS file
#For more information, visit http://archive.ics.uci.edu/ml/datasets/UJIIndoorLoc
#########################################################################################
#set working directory to get the resultss
setwd("C:/Users/Jeroen/Desktop/Ubiqum/IoT Analytics/Task 3 - Techniques for Wifi Locationing/Excel datafiles/Results")
#read results into R
predictions <- readRDS("2019-03-06 predicted values")
results <- readRDS("Results of loop 2019-03-06")
#add all actual y values in 1 dataframe with the results
predictions <- data.frame(predictions)
y_df_test <- data.frame(y_list_test)
all_y_values <- :lef_join(y_list_test, predictions)
all_y_values <- lef_join(y_list_test, predictions)
all_y_values <- left_join(y_list_test, predictions)
all_y_values <- left_join(y_df_test, predictions)
#add all actual y values in 1 dataframe with the results
predictions <- data.frame(predictions)
y_df_test <- data.frame(y_list_test)
predictions$ID <- seq.int(nrow(predictions))
y_df_test$ID <- seq.int(nrow(y_df_test))
all_y_values <- left_join(y_df_test, predictions, by = "ID")
remove(y_list_test, y_df_test, predictions)
#plot results
ggplot(all_y_values) +
geom_point(aes(x = LONGITUDE, y = LATITUDE)) +
geom_point(aes(x = knn_predict_LONGITUDE, y = knn_predict_LATITUDE, colour = BUILDINGID))
#plot results
ggplot(all_y_values) +
geom_point(aes(x = LONGITUDE, y = LATITUDE)) +
geom_point(aes(x = rf_predict_LONGITUDE, y = rf_predict_LATITUDE, colour = BUILDINGID))
#plot results
ggplot(all_y_values) +
geom_point(aes(x = LONGITUDE, y = LATITUDE)) +
geom_point(aes(x = gbm_predict_LONGITUDE, y = gbm_predict_LATITUDE, colour = BUILDINGID))
ggplot(all_y_values) +
geom_point(aes(x = BUILDINGID, y = FLOOR)) +
geom_point(aes(x = gbm_predict_BUILDINGID, y = gbm_predict_FLOOR, colour = BUILDINGID))
ggplot(all_y_values) +
geom_point(aes(x = BUILDINGID, y = gbm_predict_BUILDINGID))
ggplot(all_y_values) +
geom_point(aes(x = BUILDINGID, y = gbm_predict_BUILDINGID, colour = gbm_predict_BUILDINGID))
ggplot(data =  all_y_values, mapping = aes(x = BUILDINGID, y = knn_predict_BUILDINGID)) +
geom_tile(aes(fill = Y), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
scale_fill_gradient(low = "blue", high = "red") +
theme_bw() + theme(legend.position = "none")
ggplot(data =  all_y_values, mapping = aes(x = BUILDINGID, y = knn_predict_BUILDINGID)) +
geom_tile(aes(fill = knn_predict_BUILDINGID), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", knn_predict_BUILDINGID)), vjust = 1) +
scale_fill_gradient(low = "blue", high = "red") +
theme_bw() + theme(legend.position = "none")
#plot results
ggplot(all_y_values) +
geom_point(aes(x = LONGITUDE, y = LATITUDE)) +
geom_point(aes(x = gbm_predict_LONGITUDE, y = gbm_predict_LATITUDE, colour = BUILDINGID))
#plot results
ggplot(all_y_values) +
geom_point(aes(x = LONGITUDE, y = LATITUDE)) +
geom_point(aes(x = knn_predict_LONGITUDE, y = knn_predict_LATITUDE, colour = BUILDINGID))
#plot results
ggplot(all_y_values) +
geom_point(aes(x = LONGITUDE, y = LATITUDE)) +
geom_point(aes(x = rf_predict_LONGITUDE, y = rf_predict_LATITUDE, colour = BUILDINGID))
library(plotly)
source('~/.active-rstudio-document', echo=TRUE)
View(x_list_test)
View(x_list_train)
source('~/.active-rstudio-document', echo=TRUE)
source('C:/Users/Jeroen/Desktop/Ubiqum/IoT Analytics/Task 3 - Techniques for Wifi Locationing/Code/1) Partition training and testsets, testing whether the lists can be made automatically.R', echo=TRUE)
View(y_list_train)
#setup libraries
rm(list = ls())
set.seed(124)
library(ggplot2)
library(readr)
library(anytime)
library(caret)
library(dplyr)
library(rlist)
#import data
setwd("C:/Users/Jeroen/Desktop/Ubiqum/IoT Analytics/Task 3 - Techniques for Wifi Locationing/Excel datafiles")
wifi_train <- read.csv("trainingData.csv", header=TRUE, row.names=NULL, sep = ",")
wifi_test <- read.csv("validationData.csv", header=TRUE, row.names=NULL, sep = ",")
#Preprocessing
#change class of building and floor to factor
wifi_train$BUILDINGID <- as.factor(wifi_train$BUILDINGID)
wifi_train$FLOOR <- as.factor(wifi_train$FLOOR)
wifi_test$BUILDINGID <- as.factor(wifi_test$BUILDINGID)
wifi_test$FLOOR <- as.factor(wifi_test$FLOOR)
#change unix time variable to actual datetime
wifi_train$DateTime <- anytime(wifi_train$TIMESTAMP)
wifi_test$DateTime <- anytime(wifi_test$TIMESTAMP)
#how big should the data partition be?
no_rows_partition <- 1500
#which values should be added as a dependent variable?
y_names <- c("BUILDINGID", "FLOOR", "LATITUDE", "LONGITUDE")
#empty lists to be filled during the loop
x_list_train <- list()
y_list_train <- list()
x_list_test <- list()
y_list_test <- list()
#for loop that creates smaller data frames for each data dependent variable
for (i in 1:length(y_names)){
set.seed(124)
#create the data partition of the full trainingset
train_id <- createDataPartition(y = wifi_train[,c(y_names[i])],
p = no_rows_partition/nrow(wifi_train),
list = FALSE)
#use the partition to generate the training set that will be used
training <- wifi_train[train_id,]
#remove columns without variance in both test and training set
testing <- wifi_test[-which(apply(training, 2, var) == 0)]
training <- training[-which(apply(training, 2, var) == 0)]
#store the training & test set under a seperate name
assign(paste("train_set_", y_names[i], sep = ""), training)
assign(paste("test_set_", y_names[i], sep = ""), testing)
#save the training and testsets as an rds file
saveRDS(training, file = paste("train_set_", y_names[i]))
saveRDS(testing, file = paste("test_set_", y_names[i]))
#seperate x and y values for each training dataframe
#this makes the df for the independent variables (x)
throwaway_train_x <- training[ , grepl( "WAP" , names(training))]
x_list_train <- list.append(x_list_train, assign(paste("x_train_",
y_names[i],
sep = ""),
throwaway_train_x))
#this makes the df for the dependent variable (y)
throwaway_train_y <- training[y_names[i]]
y_list_train <- list.append(y_list_train, assign(paste("x_train_",
y_names[i],
sep = "")
,throwaway_train_y))
#seperate x and y values for each test dataframe
#this makes the df for the dependent variable (x)
throwaway_test_x <- testing[ , grepl( "WAP" , names(testing))]
x_list_test <- list.append(x_list_test, assign(paste("x_test_",
y_names[i],
sep = ""),
throwaway_test_x))
#this makes the df for the dependent test variable (y)
throwaway_test_y <- testing[y_names[i]]
y_list_test <- list.append(y_list_test, assign(paste("y_test_",
y_names[i],
sep = ""),
throwaway_test_y))
remove(training)
remove(testing)
remove(throwaway_train_x)
remove(throwaway_train_y)
remove(throwaway_test_x)
remove(throwaway_test_y)
}
Sys.setenv(temporary)
Sys.setenv("temporary")
Sys.setenv( temporary = "TEMP")
Sys.getenv()
Sys.getenv(temporary)
Sys.getenv("temporary")
Sys.unsetenv("R_TEST")
Sys.setenv(temporary = "TEMP")
Sys.unsetenv("R_TEST")
Sys.getenv("temporary")
Sys.unsetenv("R_TEST")
Sys.getenv("temporary")
Sys.unsetenv("temporary")
Sys.getenv("temporary")
Sys.getenv("hai")
assign("hello", 1+1)
assign("hello", 1+1, envir = temporary)
Sys.setenv(temporary = "TEMP")
assign("hello", 1+1, envir = temporary)
assign("hello", 1+1, envir = NULL)
assign("hello", 1+1, envir = FALSE)
tempname <- "fagafaga"
tempdf <- data.frame(c(1:10))
tempdf
class(tempdf)
tempname <- tempdf
tempname
tempdf
tempname <- "fagafaga"
tempdf <- data.frame(c(1:10))
wifi_train[ , grepl( "WAP" , names(training)
wifi_train[ , grepl( "WAP" , names(training)]
wifi_train[ , grepl( "WAP" , names(wifi_train)]
wifi_train[ , grepl( "WAP" , names(wifi_train)
wifi_train[ , grepl( "WAP" , names(wifi_train))]
wifi_train[ , grepl( "WAP" , names(wifi_train))]
wifi_train %>% filter(wifi_train[ , grepl( "WAP" , names(wifi_train))] == 100)
wifi_train %>% filter((wifi_train[ , grepl( "WAP" , names(wifi_train))]) == 100)
filter((wifi_train[ , grepl( "WAP" , names(wifi_train))]) == 100)
filter((wifi_train[ , grepl( "WAP" , names(wifi_train))]) == 100) <- 0
View(wifi_train)
